[
  {
    "id": "t3_1rco6go",
    "parsedId": "1rco6go",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1rco6go/d_is_the_move_toward_energybased_models_for/",
    "username": "cuyeyo",
    "userId": "t2_a21hw6l8",
    "title": "[D] Is the move toward Energy-Based Models for reasoning a viable exit from the \"hallucination\" trap of LLMs?",
    "communityName": "r/MachineLearning",
    "parsedCommunityName": "MachineLearning",
    "body": "I've been stuck on the recent back-and-forth between Yann LeCun and Demis Hassabis, especially the part about whether LLMs are just \"approximate Turing Machines\" or a fundamental dead end for true reasoning. It's pretty wild to see LeCun finally putting his money where his mouth is by chairing the board at Logical Intelligence, which seems to be moving away from the autoregressive paradigm entirely.\n\nThey're building an architecture called Kona that's rooted in [Energy-Based Models](https://logicalintelligence.com/kona-ebms-energy-based-models). The idea of reasoning via energy minimization instead of next-token prediction is technically interesting because it treats a solution like a physical system seeking equilibrium rather than just a string of guessed words. I was reading [this Wired piece about the shift they're making](https://www.wired.com/story/logical-intelligence-yann-lecun-startup-chart-new-course-agi/), and it really highlights the tension between \"System 1\" generation and \"System 2\" optimization.\n\nIf Kona can actually enforce hard logical constraints through these [EBMs](https://logicalintelligence.com/kona-ebms-energy-based-models), it might finally solve the reliability problem, but I'm still skeptical about the inference-time cost and the scaling laws involved. We all know why autoregressive models won - they are incredibly easy to scale and train. Shifting back to an optimization-first architecture like what Logical Intelligence is doing feels like a high-stakes bet on the \"physics\" of reasoning over the \"fluency\" of language.\n\nBasically, are we ever going to see Energy-Based Models hit the mainstream, or is the 'scale-everything-autoregressive' train moving too fast for anything like Kona to catch up?",
    "link": "https://www.reddit.com/r/MachineLearning/comments/1rco6go/d_is_the_move_toward_energybased_models_for/",
    "numberOfComments": 22,
    "flair": "Discussion",
    "upVotes": 72,
    "upVoteRatio": 0.9,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "createdAt": "2026-02-23T17:42:07.000Z",
    "scrapedAt": "2026-02-24T07:28:16.144Z",
    "dataType": "post"
  },
  {
    "id": "t3_1rcxj45",
    "parsedId": "1rcxj45",
    "url": "https://www.reddit.com/r/artificial/comments/1rcxj45/ibm_stock_tumbles_10_after_anthropic_launches/",
    "username": "esporx",
    "userId": "t2_jhjll",
    "title": "IBM stock tumbles 10% after Anthropic launches COBOL AI tool",
    "communityName": "r/artificial",
    "parsedCommunityName": "artificial",
    "body": "Images:\n\thttps://external-preview.redd.it/M3utst2Oji1hCt3m8AnFj_FOc4JYhqto5p-e1VjQqZA.png?auto=webp&s=4022ca3382f889983614a1e2ac9c50ca08716c26\n",
    "link": "https://finance.yahoo.com/news/ibm-stock-tumbles-10-anthropic-194042677.html",
    "numberOfComments": 51,
    "flair": "News",
    "upVotes": 329,
    "upVoteRatio": 0.97,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "createdAt": "2026-02-23T23:21:42.000Z",
    "scrapedAt": "2026-02-24T07:28:17.744Z",
    "dataType": "post"
  },
  {
    "id": "t3_1rcgmrh",
    "parsedId": "1rcgmrh",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1rcgmrh/r_neural_pde_solvers_built_almost_purely_from/",
    "username": "t_msr",
    "userId": "t2_271j5m41zq",
    "title": "[R] Neural PDE solvers built (almost) purely from learned warps",
    "communityName": "r/MachineLearning",
    "parsedCommunityName": "MachineLearning",
    "body": "Full Disclaimer: This is my own work.\n\nTL;DR: We built a neural PDE solver entirely from learned coordinate warps (no fourier layers, no attention, (almost) no spatial convolutions). It easily outperforms all other models at a comparable scale on a wide selection of problems from The Well. For a visual TL;DR see the Project Page: [link](https://till-m.github.io/flowers/)\n\nPaper: [RG](https://www.researchgate.net/publication/400979038_Flowers_A_Warp_Drive_for_Neural_PDE_Solvers)\n\nCode: [GitHub](https://github.com/till-m/flowers/)",
    "link": "https://www.reddit.com/r/MachineLearning/comments/1rcgmrh/r_neural_pde_solvers_built_almost_purely_from/",
    "numberOfComments": 13,
    "flair": "Research",
    "upVotes": 60,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "createdAt": "2026-02-23T12:53:35.000Z",
    "scrapedAt": "2026-02-24T07:28:20.144Z",
    "dataType": "post"
  },
  {
    "id": "t3_1rcmgzy",
    "parsedId": "1rcmgzy",
    "url": "https://www.reddit.com/r/artificial/comments/1rcmgzy/big_tech_to_invest_about_650_billion_in_ai_in/",
    "username": "Secure-Address4385",
    "userId": "t2_1zjooy1v0c",
    "title": "Big Tech to invest about $650 billion in AI in 2026, Bridgewater says",
    "communityName": "r/artificial",
    "parsedCommunityName": "artificial",
    "body": "Images:\n\thttps://external-preview.redd.it/qWpbbeWsWPYTc60iK5nFzmpYnD1ucCW41qV4k46wB98.jpeg?auto=webp&s=a0b576e368c6edf252db30ad9e2bbeebcbcbaa19\n",
    "link": "https://www.reuters.com/business/big-tech-invest-about-650-billion-ai-2026-bridgewater-says-2026-02-23/",
    "numberOfComments": 27,
    "flair": "News",
    "upVotes": 53,
    "upVoteRatio": 0.89,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "createdAt": "2026-02-23T16:42:18.000Z",
    "scrapedAt": "2026-02-24T07:28:20.147Z",
    "dataType": "post"
  },
  {
    "id": "t3_1rcbrgg",
    "parsedId": "1rcbrgg",
    "url": "https://www.reddit.com/r/artificial/comments/1rcbrgg/the_prompt_format_that_consistently_beats/",
    "username": "Difficult-Sugar-4862",
    "userId": "t2_3yfaa6kk",
    "title": "The prompt format that consistently beats free-form asking and why structure matters more than creativity",
    "communityName": "r/artificial",
    "parsedCommunityName": "artificial",
    "body": "I've written 365+ prompts for enterprise use and the pattern is clear: structured prompts with boring, predictable formatting outperform creative or \"clever\" prompts every single time especially for professional settings.\n\n**What do I mean by structure:**\n\nEvery prompt I've built follows the same skeleton:\n- Who are you ? (role/context)\n- What do you need? (specific task)\n- Constraints (what's in/out of scope)\n- Output format (exactly how you want it delivered)\n\n**Why \"creative\" prompts fail in enterprise:**\n\n1. **They're not repeatable** : If a clever prompt works for me but my colleague can't modify it for their use case, it's useless at scale.\n\n2. **They're hard to debug** : When a structured prompt gives bad output, you can identify which section needs fixing. When a creative prompt fails, you're starting from scratch.\n\n3. **They don't transfer across models** : A prompt that exploits a specific model's quirks breaks when you switch from GPT-4.1 to Claude to Copilot. Structure-based prompts transfer cleanly.\n\n4. **They can't be governed** : IT and compliance teams need to review and approve prompt templates. \"Just ask it creatively\" isn't a policy.\n\n**The boring truth about prompt engineering:**\n\nIt's not engineering and it's not an art. It's technical writing. The same skills that make good documentation make good prompts: clarity, specificity, structure, and knowing your audience.\n\nThe best prompt engineers I've met aren't AI researchers they're former technical writers, business analysts, and process designers.\n\nAm I wrong to push for standardization over creativity?",
    "link": "https://www.reddit.com/r/artificial/comments/1rcbrgg/the_prompt_format_that_consistently_beats/",
    "numberOfComments": 10,
    "flair": "Discussion",
    "upVotes": 5,
    "upVoteRatio": 0.67,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "createdAt": "2026-02-23T08:14:10.000Z",
    "scrapedAt": "2026-02-24T07:28:25.144Z",
    "dataType": "post"
  },
  {
    "id": "t3_1rcb3sa",
    "parsedId": "1rcb3sa",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1rcb3sa/d_cvpr_results_shock_due_to_impressive_score_drop/",
    "username": "MrLeylo",
    "userId": "t2_d7fm7",
    "title": "[D] CVPR results shock due to impressive score drop since reviews",
    "communityName": "r/MachineLearning",
    "parsedCommunityName": "MachineLearning",
    "body": "CVPR decisions came out and I'm shocked. I got previously a 6(5)/4(4)/2(4). The first reviewer was enthusiastic, the second had concerns and the third heavier concerns. ONE of the concerns of the third is that I didn't upload the results to an online benchmark in my field, I made the petition to the platform and I informed about this being done in the rebuttal.\n\nThey lowered to 4/2/2. The first said that yes he liked the method but the online submission should have been done. The second said he was not convinced on the response (although I addressed carefully his concerns!). And the third stayed. In my head I can't process that two of them, who liked the method, lowered! (I was expecting reviewer 2 to raise the score, maybe that wouldn't happen but lowering it??). The AC mentioned the benchmark issue, may he have influenced the rest of reviewers? Do you find it plausible?\n\nEdit: Context: the benchmark matter was only mentioned by the third...",
    "link": "https://www.reddit.com/r/MachineLearning/comments/1rcb3sa/d_cvpr_results_shock_due_to_impressive_score_drop/",
    "numberOfComments": 19,
    "flair": "Discussion",
    "upVotes": 34,
    "upVoteRatio": 0.86,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "createdAt": "2026-02-23T07:33:16.000Z",
    "scrapedAt": "2026-02-24T07:28:25.240Z",
    "dataType": "post"
  }
]
